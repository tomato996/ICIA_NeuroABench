# ICIA_NeuroABench

## ğŸ“ Overview
Our paper introduces NeuroABench, a new multimodal benchmark for evaluating anatomical understanding in neurosurgical videos, and finds that while state-of-the-art multimodal large language models show promise, they still fall short of human-level performance in anatomical identification tasks.
<figure>
  <img src="IMAGE/method1.jpg" alt="The reward and S(q) curves of the Qwen-2.5-VL-7B during training on the SGG-VQA dataset." width="480"/>
  <figcaption><b>Figure 1:</b> The reward and S(q) curves of the Qwen-2.5-VL-7B during training on the SGG-VQA dataset.</figcaption>
</figure>
